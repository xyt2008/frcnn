name: "rfcn_resnext101-32x4d"
layer {
  name: "input-data"
  type: "FrcnnRoiData"
  top: "data"
  top: "im_info"
  top: "gt_boxes"
  include {
    phase: TRAIN
  }
  window_data_param {
    source: "/home/gpu02/fyk/RSI-mix/RSI-mix-3.trainval"
    config: "exp/fpn-det/mix_config.json"
    root_folder: "/home/gpu02/fyk/RSI-mix/images/"
    cache_images: true
    #cache_images: false
  }
}

################## resnext50-32x4d #################
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 64
    kernel_size: 7
    stride: 2
    pad: 3
    bias_term: false
  }
}
layer {
  name: "conv1_scale"
  bottom: "conv1"
  top: "conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "conv1_relu"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "pool1"
  type: "Pooling"
  bottom: "conv1"
  top: "pool1"
  pooling_param {
    pool: MAX
    kernel_size: 3
    stride: 2
    pad: 1
    ceil_mode: false
  }
}

#----------- res2 -------------
layer {
  name: "resx1_conv1"
  type: "Convolution"
  bottom: "pool1"
  top: "resx1_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx1_conv1_scale"
  bottom: "resx1_conv1"
  top: "resx1_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx1_conv1_relu"
  type: "ReLU"
  bottom: "resx1_conv1"
  top: "resx1_conv1"
}
layer {
  name: "resx1_conv2"
  type: "Convolution"
  bottom: "resx1_conv1"
  top: "resx1_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    group: 32
    pad: 1
    bias_term: false
  }
}
layer {
  name: "resx1_conv2_scale"
  bottom: "resx1_conv2"
  top: "resx1_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx1_conv2_relu"
  type: "ReLU"
  bottom: "resx1_conv2"
  top: "resx1_conv2"
}
layer {
  name: "resx1_conv3"
  type: "Convolution"
  bottom: "resx1_conv2"
  top: "resx1_conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx1_conv3_scale"
  bottom: "resx1_conv3"
  top: "resx1_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx1_match_conv"
  type: "Convolution"
  bottom: "pool1"
  top: "resx1_match_conv"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx1_match_conv_scale"
  bottom: "resx1_match_conv"
  top: "resx1_match_conv"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx1_elewise"
  type: "Eltwise"
  bottom: "resx1_match_conv"
  bottom: "resx1_conv3"
  top: "resx1_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resx1_elewise_relu"
  type: "ReLU"
  bottom: "resx1_elewise"
  top: "resx1_elewise"
}
layer {
  name: "resx2_conv1"
  type: "Convolution"
  bottom: "resx1_elewise"
  top: "resx2_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx2_conv1_scale"
  bottom: "resx2_conv1"
  top: "resx2_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx2_conv1_relu"
  type: "ReLU"
  bottom: "resx2_conv1"
  top: "resx2_conv1"
}
layer {
  name: "resx2_conv2"
  type: "Convolution"
  bottom: "resx2_conv1"
  top: "resx2_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    group: 32
    pad: 1
    bias_term: false
  }
}
layer {
  name: "resx2_conv2_scale"
  bottom: "resx2_conv2"
  top: "resx2_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx2_conv2_relu"
  type: "ReLU"
  bottom: "resx2_conv2"
  top: "resx2_conv2"
}
layer {
  name: "resx2_conv3"
  type: "Convolution"
  bottom: "resx2_conv2"
  top: "resx2_conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx2_conv3_scale"
  bottom: "resx2_conv3"
  top: "resx2_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx2_elewise"
  type: "Eltwise"
  bottom: "resx1_elewise"
  bottom: "resx2_conv3"
  top: "resx2_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resx2_elewise_relu"
  type: "ReLU"
  bottom: "resx2_elewise"
  top: "resx2_elewise"
}
layer {
  name: "resx3_conv1"
  type: "Convolution"
  bottom: "resx2_elewise"
  top: "resx3_conv1"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx3_conv1_scale"
  bottom: "resx3_conv1"
  top: "resx3_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx3_conv1_relu"
  type: "ReLU"
  bottom: "resx3_conv1"
  top: "resx3_conv1"
}
layer {
  name: "resx3_conv2"
  type: "Convolution"
  bottom: "resx3_conv1"
  top: "resx3_conv2"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 128
    kernel_size: 3
    stride: 1
    group: 32
    pad: 1
    bias_term: false
  }
}
layer {
  name: "resx3_conv2_scale"
  bottom: "resx3_conv2"
  top: "resx3_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx3_conv2_relu"
  type: "ReLU"
  bottom: "resx3_conv2"
  top: "resx3_conv2"
}
layer {
  name: "resx3_conv3"
  type: "Convolution"
  bottom: "resx3_conv2"
  top: "resx3_conv3"
  param {
    lr_mult: 0
    decay_mult: 0
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx3_conv3_scale"
  bottom: "resx3_conv3"
  top: "resx3_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx3_elewise"
  type: "Eltwise"
  bottom: "resx2_elewise"
  bottom: "resx3_conv3"
  top: "resx3_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resx3_elewise_relu"
  type: "ReLU"
  bottom: "resx3_elewise"
  top: "resx3_elewise"
}
#----------- res3 -------------
layer {
  name: "resx4_conv1"
  type: "Convolution"
  bottom: "resx3_elewise"
  top: "resx4_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx4_conv1_scale"
  bottom: "resx4_conv1"
  top: "resx4_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx4_conv1_relu"
  type: "ReLU"
  bottom: "resx4_conv1"
  top: "resx4_conv1"
}
layer {
  name: "resx4_conv2"
  type: "Convolution"
  bottom: "resx4_conv1"
  top: "resx4_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 2
    group: 32
    pad: 1
    bias_term: false
  }
}
layer {
  name: "resx4_conv2_scale"
  bottom: "resx4_conv2"
  top: "resx4_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx4_conv2_relu"
  type: "ReLU"
  bottom: "resx4_conv2"
  top: "resx4_conv2"
}
layer {
  name: "resx4_conv3"
  type: "Convolution"
  bottom: "resx4_conv2"
  top: "resx4_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx4_conv3_scale"
  bottom: "resx4_conv3"
  top: "resx4_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx4_match_conv"
  type: "Convolution"
  bottom: "resx3_elewise"
  top: "resx4_match_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 2
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx4_match_conv_scale"
  bottom: "resx4_match_conv"
  top: "resx4_match_conv"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx4_elewise"
  type: "Eltwise"
  bottom: "resx4_match_conv"
  bottom: "resx4_conv3"
  top: "resx4_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resx4_elewise_relu"
  type: "ReLU"
  bottom: "resx4_elewise"
  top: "resx4_elewise"
}
layer {
  name: "resx5_conv1"
  type: "Convolution"
  bottom: "resx4_elewise"
  top: "resx5_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx5_conv1_scale"
  bottom: "resx5_conv1"
  top: "resx5_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx5_conv1_relu"
  type: "ReLU"
  bottom: "resx5_conv1"
  top: "resx5_conv1"
}
layer {
  name: "resx5_conv2"
  type: "Convolution"
  bottom: "resx5_conv1"
  top: "resx5_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    group: 32
    pad: 1
    bias_term: false
  }
}
layer {
  name: "resx5_conv2_scale"
  bottom: "resx5_conv2"
  top: "resx5_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx5_conv2_relu"
  type: "ReLU"
  bottom: "resx5_conv2"
  top: "resx5_conv2"
}
layer {
  name: "resx5_conv3"
  type: "Convolution"
  bottom: "resx5_conv2"
  top: "resx5_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx5_conv3_scale"
  bottom: "resx5_conv3"
  top: "resx5_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx5_elewise"
  type: "Eltwise"
  bottom: "resx4_elewise"
  bottom: "resx5_conv3"
  top: "resx5_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resx5_elewise_relu"
  type: "ReLU"
  bottom: "resx5_elewise"
  top: "resx5_elewise"
}
layer {
  name: "resx6_conv1"
  type: "Convolution"
  bottom: "resx5_elewise"
  top: "resx6_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx6_conv1_scale"
  bottom: "resx6_conv1"
  top: "resx6_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx6_conv1_relu"
  type: "ReLU"
  bottom: "resx6_conv1"
  top: "resx6_conv1"
}
layer {
  name: "resx6_conv2"
  type: "Convolution"
  bottom: "resx6_conv1"
  top: "resx6_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    group: 32
    pad: 1
    bias_term: false
  }
}
layer {
  name: "resx6_conv2_scale"
  bottom: "resx6_conv2"
  top: "resx6_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx6_conv2_relu"
  type: "ReLU"
  bottom: "resx6_conv2"
  top: "resx6_conv2"
}
layer {
  name: "resx6_conv3"
  type: "Convolution"
  bottom: "resx6_conv2"
  top: "resx6_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx6_conv3_scale"
  bottom: "resx6_conv3"
  top: "resx6_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx6_elewise"
  type: "Eltwise"
  bottom: "resx5_elewise"
  bottom: "resx6_conv3"
  top: "resx6_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resx6_elewise_relu"
  type: "ReLU"
  bottom: "resx6_elewise"
  top: "resx6_elewise"
}
layer {
  name: "resx7_conv1"
  type: "Convolution"
  bottom: "resx6_elewise"
  top: "resx7_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx7_conv1_scale"
  bottom: "resx7_conv1"
  top: "resx7_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx7_conv1_relu"
  type: "ReLU"
  bottom: "resx7_conv1"
  top: "resx7_conv1"
}
layer {
  name: "resx7_conv2"
  type: "Convolution"
  bottom: "resx7_conv1"
  top: "resx7_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 256
    kernel_size: 3
    stride: 1
    group: 32
    pad: 1
    bias_term: false
  }
}
layer {
  name: "resx7_conv2_scale"
  bottom: "resx7_conv2"
  top: "resx7_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx7_conv2_relu"
  type: "ReLU"
  bottom: "resx7_conv2"
  top: "resx7_conv2"
}
layer {
  name: "resx7_conv3"
  type: "Convolution"
  bottom: "resx7_conv2"
  top: "resx7_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx7_conv3_scale"
  bottom: "resx7_conv3"
  top: "resx7_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx7_elewise"
  type: "Eltwise"
  bottom: "resx6_elewise"
  bottom: "resx7_conv3"
  top: "resx7_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resx7_elewise_relu"
  type: "ReLU"
  bottom: "resx7_elewise"
  top: "resx7_elewise"
}
#----------- res4 -------------
layer {
  name: "resx8_conv1"
  type: "Convolution"
  bottom: "resx7_elewise"
  top: "resx8_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx8_conv1_scale"
  bottom: "resx8_conv1"
  top: "resx8_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx8_conv1_relu"
  type: "ReLU"
  bottom: "resx8_conv1"
  top: "resx8_conv1"
}
layer {
  name: "resx8_conv2"
  type: "Convolution"
  bottom: "resx8_conv1"
  top: "resx8_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 2
    group: 32
    pad: 1
    bias_term: false
  }
}
layer {
  name: "resx8_conv2_scale"
  bottom: "resx8_conv2"
  top: "resx8_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx8_conv2_relu"
  type: "ReLU"
  bottom: "resx8_conv2"
  top: "resx8_conv2"
}
layer {
  name: "resx8_conv3"
  type: "Convolution"
  bottom: "resx8_conv2"
  top: "resx8_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx8_conv3_scale"
  bottom: "resx8_conv3"
  top: "resx8_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx8_match_conv"
  type: "Convolution"
  bottom: "resx7_elewise"
  top: "resx8_match_conv"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 2
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx8_match_conv_scale"
  bottom: "resx8_match_conv"
  top: "resx8_match_conv"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx8_elewise"
  type: "Eltwise"
  bottom: "resx8_conv3"
  bottom: "resx8_match_conv"
  top: "resx8_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resx8_elewise_relu"
  type: "ReLU"
  bottom: "resx8_elewise"
  top: "resx8_elewise"
}
layer {
  name: "resx9_conv1"
  type: "Convolution"
  bottom: "resx8_elewise"
  top: "resx9_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx9_conv1_scale"
  bottom: "resx9_conv1"
  top: "resx9_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx9_conv1_relu"
  type: "ReLU"
  bottom: "resx9_conv1"
  top: "resx9_conv1"
}
layer {
  name: "resx9_conv2"
  type: "Convolution"
  bottom: "resx9_conv1"
  top: "resx9_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    group: 32
    pad: 1
    bias_term: false
  }
}
layer {
  name: "resx9_conv2_scale"
  bottom: "resx9_conv2"
  top: "resx9_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx9_conv2_relu"
  type: "ReLU"
  bottom: "resx9_conv2"
  top: "resx9_conv2"
}
layer {
  name: "resx9_conv3"
  type: "Convolution"
  bottom: "resx9_conv2"
  top: "resx9_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx9_conv3_scale"
  bottom: "resx9_conv3"
  top: "resx9_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx9_elewise"
  type: "Eltwise"
  bottom: "resx8_elewise"
  bottom: "resx9_conv3"
  top: "resx9_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resx9_elewise_relu"
  type: "ReLU"
  bottom: "resx9_elewise"
  top: "resx9_elewise"
}
layer {
  name: "resx10_conv1"
  type: "Convolution"
  bottom: "resx9_elewise"
  top: "resx10_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx10_conv1_scale"
  bottom: "resx10_conv1"
  top: "resx10_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx10_conv1_relu"
  type: "ReLU"
  bottom: "resx10_conv1"
  top: "resx10_conv1"
}
layer {
  name: "resx10_conv2"
  type: "Convolution"
  bottom: "resx10_conv1"
  top: "resx10_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    group: 32
    pad: 1
    bias_term: false
  }
}
layer {
  name: "resx10_conv2_scale"
  bottom: "resx10_conv2"
  top: "resx10_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx10_conv2_relu"
  type: "ReLU"
  bottom: "resx10_conv2"
  top: "resx10_conv2"
}
layer {
  name: "resx10_conv3"
  type: "Convolution"
  bottom: "resx10_conv2"
  top: "resx10_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx10_conv3_scale"
  bottom: "resx10_conv3"
  top: "resx10_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx10_elewise"
  type: "Eltwise"
  bottom: "resx9_elewise"
  bottom: "resx10_conv3"
  top: "resx10_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resx10_elewise_relu"
  type: "ReLU"
  bottom: "resx10_elewise"
  top: "resx10_elewise"
}
layer {
  name: "resx11_conv1"
  type: "Convolution"
  bottom: "resx10_elewise"
  top: "resx11_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx11_conv1_scale"
  bottom: "resx11_conv1"
  top: "resx11_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx11_conv1_relu"
  type: "ReLU"
  bottom: "resx11_conv1"
  top: "resx11_conv1"
}
layer {
  name: "resx11_conv2"
  type: "Convolution"
  bottom: "resx11_conv1"
  top: "resx11_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    group: 32
    pad: 1
    bias_term: false
  }
}
layer {
  name: "resx11_conv2_scale"
  bottom: "resx11_conv2"
  top: "resx11_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx11_conv2_relu"
  type: "ReLU"
  bottom: "resx11_conv2"
  top: "resx11_conv2"
}
layer {
  name: "resx11_conv3"
  type: "Convolution"
  bottom: "resx11_conv2"
  top: "resx11_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx11_conv3_scale"
  bottom: "resx11_conv3"
  top: "resx11_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx11_elewise"
  type: "Eltwise"
  bottom: "resx10_elewise"
  bottom: "resx11_conv3"
  top: "resx11_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resx11_elewise_relu"
  type: "ReLU"
  bottom: "resx11_elewise"
  top: "resx11_elewise"
}
layer {
  name: "resx12_conv1"
  type: "Convolution"
  bottom: "resx11_elewise"
  top: "resx12_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx12_conv1_scale"
  bottom: "resx12_conv1"
  top: "resx12_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx12_conv1_relu"
  type: "ReLU"
  bottom: "resx12_conv1"
  top: "resx12_conv1"
}
layer {
  name: "resx12_conv2"
  type: "Convolution"
  bottom: "resx12_conv1"
  top: "resx12_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    group: 32
    pad: 1
    bias_term: false
  }
}
layer {
  name: "resx12_conv2_scale"
  bottom: "resx12_conv2"
  top: "resx12_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx12_conv2_relu"
  type: "ReLU"
  bottom: "resx12_conv2"
  top: "resx12_conv2"
}
layer {
  name: "resx12_conv3"
  type: "Convolution"
  bottom: "resx12_conv2"
  top: "resx12_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx12_conv3_scale"
  bottom: "resx12_conv3"
  top: "resx12_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx12_elewise"
  type: "Eltwise"
  bottom: "resx11_elewise"
  bottom: "resx12_conv3"
  top: "resx12_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resx12_elewise_relu"
  type: "ReLU"
  bottom: "resx12_elewise"
  top: "resx12_elewise"
}
layer {
  name: "resx13_conv1"
  type: "Convolution"
  bottom: "resx12_elewise"
  top: "resx13_conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx13_conv1_scale"
  bottom: "resx13_conv1"
  top: "resx13_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx13_conv1_relu"
  type: "ReLU"
  bottom: "resx13_conv1"
  top: "resx13_conv1"
}
layer {
  name: "resx13_conv2"
  type: "Convolution"
  bottom: "resx13_conv1"
  top: "resx13_conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    stride: 1
    group: 32
    pad: 1
    bias_term: false
  }
}
layer {
  name: "resx13_conv2_scale"
  bottom: "resx13_conv2"
  top: "resx13_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx13_conv2_relu"
  type: "ReLU"
  bottom: "resx13_conv2"
  top: "resx13_conv2"
}
layer {
  name: "resx13_conv3"
  type: "Convolution"
  bottom: "resx13_conv2"
  top: "resx13_conv3"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx13_conv3_scale"
  bottom: "resx13_conv3"
  top: "resx13_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
  param {
    lr_mult: 0.0
    decay_mult: 0.0
  }
}
layer {
  name: "resx13_elewise"
  type: "Eltwise"
  bottom: "resx12_elewise"
  bottom: "resx13_conv3"
  top: "resx13_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resx13_elewise_relu"
  type: "ReLU"
  bottom: "resx13_elewise"
  top: "resx13_elewise"
}

#----------- res5 -------------
layer {
  name: "resx14_conv1"
  type: "Convolution"
  bottom: "resx13_elewise"
  top: "resx14_conv1"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx14_conv1_scale"
  bottom: "resx14_conv1"
  top: "resx14_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx14_conv1_relu"
  type: "ReLU"
  bottom: "resx14_conv1"
  top: "resx14_conv1"
}
layer {
  name: "resx14_conv2"
  type: "Convolution"
  bottom: "resx14_conv1"
  top: "resx14_conv2"
  convolution_param {
    num_output: 1024
    kernel_size: 3
    stride: 1
    group: 32
    pad: 2
    dilation: 2
    bias_term: false
  }
}
layer {
  name: "resx14_conv2_scale"
  bottom: "resx14_conv2"
  top: "resx14_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx14_conv2_relu"
  type: "ReLU"
  bottom: "resx14_conv2"
  top: "resx14_conv2"
}
layer {
  name: "resx14_conv3"
  type: "Convolution"
  bottom: "resx14_conv2"
  top: "resx14_conv3"
  convolution_param {
    num_output: 2048
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx14_conv3_scale"
  bottom: "resx14_conv3"
  top: "resx14_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx14_match_conv"
  type: "Convolution"
  bottom: "resx13_elewise"
  top: "resx14_match_conv"
  convolution_param {
    num_output: 2048
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx14_match_conv_scale"
  bottom: "resx14_match_conv"
  top: "resx14_match_conv"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx14_elewise"
  type: "Eltwise"
  bottom: "resx14_match_conv"
  bottom: "resx14_conv3"
  top: "resx14_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resx14_elewise_relu"
  type: "ReLU"
  bottom: "resx14_elewise"
  top: "resx14_elewise"
}
layer {
  name: "resx15_conv1"
  type: "Convolution"
  bottom: "resx14_elewise"
  top: "resx15_conv1"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx15_conv1_scale"
  bottom: "resx15_conv1"
  top: "resx15_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx15_conv1_relu"
  type: "ReLU"
  bottom: "resx15_conv1"
  top: "resx15_conv1"
}
layer {
  name: "resx15_conv2"
  type: "Convolution"
  bottom: "resx15_conv1"
  top: "resx15_conv2"
  convolution_param {
    num_output: 1024
    kernel_size: 3
    stride: 1
    group: 32
    pad: 2
    dilation: 2
    bias_term: false
  }
}
layer {
  name: "resx15_conv2_scale"
  bottom: "resx15_conv2"
  top: "resx15_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx15_conv2_relu"
  type: "ReLU"
  bottom: "resx15_conv2"
  top: "resx15_conv2"
}
layer {
  name: "resx15_conv3"
  type: "Convolution"
  bottom: "resx15_conv2"
  top: "resx15_conv3"
  convolution_param {
    num_output: 2048
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx15_conv3_scale"
  bottom: "resx15_conv3"
  top: "resx15_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx15_elewise"
  type: "Eltwise"
  bottom: "resx14_elewise"
  bottom: "resx15_conv3"
  top: "resx15_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resx15_elewise_relu"
  type: "ReLU"
  bottom: "resx15_elewise"
  top: "resx15_elewise"
}
layer {
  name: "resx16_conv1"
  type: "Convolution"
  bottom: "resx15_elewise"
  top: "resx16_conv1"
  convolution_param {
    num_output: 1024
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx16_conv1_scale"
  bottom: "resx16_conv1"
  top: "resx16_conv1"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx16_conv1_relu"
  type: "ReLU"
  bottom: "resx16_conv1"
  top: "resx16_conv1"
}
layer {
  name: "resx16_conv2"
  type: "Convolution"
  bottom: "resx16_conv1"
  top: "resx16_conv2"
  convolution_param {
    num_output: 1024
    kernel_size: 3
    stride: 1
    group: 32
    pad: 2
    dilation: 2
    bias_term: false
  }
}
layer {
  name: "resx16_conv2_scale"
  bottom: "resx16_conv2"
  top: "resx16_conv2"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx16_conv2_relu"
  type: "ReLU"
  bottom: "resx16_conv2"
  top: "resx16_conv2"
}
layer {
  name: "resx16_conv3"
  type: "Convolution"
  bottom: "resx16_conv2"
  top: "resx16_conv3"
  convolution_param {
    num_output: 2048
    kernel_size: 1
    stride: 1
    pad: 0
    bias_term: false
  }
}
layer {
  name: "resx16_conv3_scale"
  bottom: "resx16_conv3"
  top: "resx16_conv3"
  type: "Scale"
  scale_param {
    bias_term: true
  }
}
layer {
  name: "resx16_elewise"
  type: "Eltwise"
  bottom: "resx15_elewise"
  bottom: "resx16_conv3"
  top: "resx16_elewise"
  eltwise_param {
    operation: SUM
  }
}
layer {
  name: "resx16_elewise_relu"
  type: "ReLU"
  bottom: "resx16_elewise"
  top: "resx16_elewise"
}
#----------- res5 end -------------
#=====the output of stage 2~5 are resx3,7,13,16=====

#========= RPN ============
layer {
  name: "rpn_conv_3x3"
  type: "Convolution"
  bottom: "resx16_elewise"
  top: "rpn_output"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 512
    kernel_size: 3
    pad: 1
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_relu_3x3"
  type: "ReLU"
  bottom: "rpn_output"
  top: "rpn_output"
}
layer {
  name: "rpn_cls_score"
  type: "Convolution"
  bottom: "rpn_output"
  top: "rpn_cls_score"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 30   # 2(bg/fg) * 15(anchors)
    kernel_size: 1
    pad: 0
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "rpn_bbox_pred"
  type: "Convolution"
  bottom: "rpn_output"
  top: "rpn_bbox_pred"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 60   # 4 * 15(anchors)
    kernel_size: 1
    pad: 0
    stride: 1
    weight_filler {
      type: "gaussian"
      std: 0.01
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  bottom: "rpn_cls_score"
  top: "rpn_cls_score_reshape"
  name: "rpn_cls_score_reshape"
  type: "Reshape"
  reshape_param {
    shape {
      dim: 0
      dim: 2
      dim: -1
      dim: 0
    }
  }
}
layer {
  name: "rpn-data"
  type: "FrcnnAnchorTarget"
  bottom: "rpn_cls_score"
  bottom: "gt_boxes"
  bottom: "im_info"
  top: "rpn_labels"
  top: "rpn_bbox_targets"
  top: "rpn_bbox_inside_weights"
  top: "rpn_bbox_outside_weights"
  propagate_down: false
  propagate_down: false
  propagate_down: false
}
layer {
  name: "rpn_loss_cls"
  type: "SoftmaxWithLoss"
  bottom: "rpn_cls_score_reshape"
  bottom: "rpn_labels"
  propagate_down: 1
  propagate_down: 0
  top: "rpn_cls_loss"
  loss_weight: 1
  loss_param {
    ignore_label: -1
    normalize: true
  }
}
layer {
  name: "rpn_loss_bbox"
  type: "SmoothL1Loss"
  bottom: "rpn_bbox_pred"
  bottom: "rpn_bbox_targets"
  bottom: 'rpn_bbox_inside_weights'
  bottom: 'rpn_bbox_outside_weights'
  top: "rpn_loss_bbox"
  loss_weight: 1
  smooth_l1_loss_param {
    sigma: 3.0
  }
}

#============== ROI Proposal ===============
layer {
  name: "rpn_cls_prob"
  type: "Softmax"
  bottom: "rpn_cls_score_reshape"
  top: "rpn_cls_prob"
}
layer {
  name: 'rpn_cls_prob_reshape'
  type: 'Reshape'
  bottom: 'rpn_cls_prob'
  top: 'rpn_cls_prob_reshape'
  reshape_param {
    shape {
      dim: 0
      dim: 30
      dim: -1
      dim: 0
    }
  }
}

layer {
  name: "proposal"
  type: "FrcnnProposal"
  bottom: "rpn_cls_prob_reshape"
  bottom: "rpn_bbox_pred"
  bottom: "im_info"
  top: "rpn_rois"
  propagate_down: false
  propagate_down: false
  propagate_down: false
}
layer {
  name: "roi-data"
  type: "FrcnnProposalTarget"
  bottom: "rpn_rois"
  bottom: "gt_boxes"
#  bottom: "im_info"
  top: "rois"
  top: "labels"
  top: "bbox_targets"
  top: "bbox_inside_weights"
  top: "bbox_outside_weights"
  propagate_down: false
  propagate_down: false
#  propagate_down: false
}

#----------------------new conv layer------------------
#large separable conv, output 'light_head', out dim 10, 5 or any number, bigger maybe better

layer {
    bottom: "resx16_elewise"
    top: "convx1_1"
    name: "convx1_1"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_h: 15
        kernel_w: 1
        pad_h: 7
        pad_w: 0
        stride: 1
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}

layer {
    bottom: "convx1_1"
    top: "convx1_2"
    name: "convx1_2"
    type: "Convolution"
    convolution_param {
        num_output: 490
        kernel_h: 1
        kernel_w: 15
        pad_h: 0
        pad_w: 7
        stride: 1
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}

layer {
    bottom: "resx16_elewise"
    top: "convx2_1"
    name: "convx2_1"
    type: "Convolution"
    convolution_param {
        num_output: 256
        kernel_h: 1
        kernel_w: 15 
        pad_h: 0
        pad_w: 7
        stride: 1
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}

layer {
    bottom: "convx2_1"
    top: "convx2_2"
    name: "convx2_2"
    type: "Convolution"
    convolution_param {
        num_output: 490
        kernel_h: 15
        kernel_w: 1
        pad_h: 7
        pad_w: 0
        stride: 1
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}

layer {
  name: "light_head"
  type: "Eltwise"
  bottom: "convx1_2"
  bottom: "convx2_2"
  top: "light_head"
}

# only one ReLU in zengarden/light_head_rcnn  implementation, we can add ReLU to each conv to add non-linear transformation ability
layer {
    bottom: "light_head"
    top: "light_head"
    name: "light_head_relu"
    type: "ReLU"
}

layer {
    bottom: "light_head"
    top: "rfcn_cls"
    name: "rfcn_cls"
    type: "Convolution"
    convolution_param {
        num_output: 294 #21*(7^2) cls_num*(score_maps_size^2)
        kernel_size: 1
        pad: 0
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}
layer {
    bottom: "light_head"
    top: "rfcn_bbox"
    name: "rfcn_bbox"
    type: "Convolution"
    convolution_param {
        num_output: 1176 # (cls+1) *4*(7^2) for class-aware 2*4*(7^2) (bg/fg)*(dx, dy, dw, dh)*(score_maps_size^2) for class-agnostic
        kernel_size: 1
        pad: 0
        weight_filler {
            type: "gaussian"
            std: 0.01
        }
        bias_filler {
            type: "constant"
            value: 0
        }
    }
    param {
        lr_mult: 1.0
    }
    param {
        lr_mult: 2.0
    }
}

#--------------position sensitive RoI pooling--------------
layer {
    bottom: "rfcn_cls"
    bottom: "rois"
    top: "psroipooled_cls_rois"
    name: "psroipooled_cls_rois"
    type: "PSROIPooling"
    psroi_pooling_param {
        spatial_scale: 0.0625
        output_dim: 6 # cls_num + 1
        group_size: 7
    }
}

layer {
    bottom: "psroipooled_cls_rois"
    top: "cls_score"
    name: "ave_cls_score_rois"
    type: "Pooling"
    pooling_param {
        pool: RCM
        kernel_size: 7
        stride: 7
        engine: CAFFE
    }
}

layer {
    bottom: "rfcn_bbox"
    bottom: "rois"
    top: "psroipooled_loc_rois"
    name: "psroipooled_loc_rois"
    type: "PSROIPooling"
    psroi_pooling_param {
        spatial_scale: 0.0625
        output_dim: 24 # (cls+1)*4 for class-aware, or 8 for class-agnostic(bg/fg)
        group_size: 7
    }
}

layer {
    bottom: "psroipooled_loc_rois"
    top: "bbox_pred"
    name: "ave_bbox_pred_rois"
    type: "Pooling"
    pooling_param {
        pool: RCM
        kernel_size: 7
        stride: 7
        engine: CAFFE
    }
}

#--------------online hard example mining--------------
layer {
   name: "per_roi_loss_cls"
   type: "SoftmaxWithLossOHEM"
   bottom: "cls_score"
   bottom: "labels"
   top: "temp_loss_cls"
   top: "temp_prob_cls"
   top: "per_roi_loss_cls"
   loss_weight: 0
   loss_weight: 0
   loss_weight: 0
   propagate_down: false
   propagate_down: false
}

layer {
   name: "per_roi_loss_bbox"
   type: "SmoothL1LossOHEM"
   bottom: "bbox_pred"
   bottom: "bbox_targets"
   bottom: "bbox_inside_weights"
   top: "temp_loss_bbox"
   top: "per_roi_loss_bbox"
   loss_weight: 0
   loss_weight: 0
   propagate_down: false
   propagate_down: false
   propagate_down: false
}

layer {
   name: "per_roi_loss"
   type: "Eltwise"
   bottom: "per_roi_loss_cls"
   bottom: "per_roi_loss_bbox"
   top: "per_roi_loss"
   propagate_down: false
   propagate_down: false
}

layer {
   bottom: "rois"
   bottom: "per_roi_loss"
   bottom: "labels"
   bottom: "bbox_inside_weights"
   top: "labels_ohem"
   top: "bbox_loss_weights_ohem"
   name: "annotator_detector"
   type: "BoxAnnotatorOHEM"
   box_annotator_ohem_param {
        roi_per_img: 128
        ignore_label: -1
   }
   propagate_down: false
   propagate_down: false
   propagate_down: false
   propagate_down: false
}

#-----------------------output------------------------

layer {
  name: "loss_cls"
  type: "SoftmaxWithLoss"
  #type: "FocalLoss" # maybe conflict with OHEM
  bottom: "cls_score"
  bottom: "labels_ohem"
  top: "loss_cls"
  loss_weight: 1.0
  loss_param { # for OHEM
        ignore_label: -1
   }
  propagate_down: true
  propagate_down: false
}
layer {
  name: "loss_bbox"
  type: "SmoothL1LossOHEM"
  bottom: "bbox_pred"
  bottom: "bbox_targets"
  #bottom: "bbox_inside_weights"
  #bottom: "bbox_outside_weights"
  bottom: "bbox_loss_weights_ohem"
  top: "loss_bbox"
  # loss_weight: 1.0
  loss_weight: 2.0 # We find that regression loss is definitely smaller that classification loss in R-CNN
  loss_param {
        normalization: PRE_FIXED
        pre_fixed_normalizer: 128
   }
   propagate_down: true
   propagate_down: false
   propagate_down: false
}
#layer {
#  name: "accuarcy"
#  type: "Accuracy"
#  bottom: "cls_score"
#  bottom: "labels_ohem"
#  top: "accuarcy"
#  accuracy_param {
#    ignore_label: -1
#  }
#  propagate_down: false
#  propagate_down: false
#}

layer {
    name: "silence"
    type: "Silence"
    bottom: "bbox_outside_weights"
    bottom: "temp_loss_cls"
    bottom: "temp_prob_cls"
    bottom: "temp_loss_bbox"
}
